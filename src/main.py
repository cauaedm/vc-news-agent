# src/main.py
import asyncio
import os
import json
import google.generativeai as genai
from tavily import TavilyClient
from crawl4ai import AsyncWebCrawler
# from openai import OpenAI # Removed OpenAI
from config import TRUSTED_SOURCES, SEARCH_TOPIC, EMAIL_TO
from email_service import send_daily_briefing
from dotenv import load_dotenv

# Carrega .env
load_dotenv()

async def crawl_urls(urls):
    """Crawl URLs using Crawl4AI."""
    print(f"ğŸ•·ï¸ Crawling {len(urls)} URLs...")
    results = []
    async with AsyncWebCrawler(verbose=True) as crawler:
        for url in urls:
            try:
                result = await crawler.arun(url=url)
                if result.success:
                     # Limita o tamanho do conteÃºdo para nÃ£o estourar o contexto do LLM
                    content_snippet = result.markdown[:4000] # Reduzido para 4k para evitar Rate Limit
                    results.append({"url": url, "content": content_snippet})
                    print(f"âœ… Crawled: {url}")
                else:
                    print(f"âŒ Failed to crawl {url}: {result.error_message}")
            except Exception as e:
                print(f"âš ï¸ Error processing {url}: {e}")
    return results

def generate_newsletter(articles):
    """Summarize articles using Google Gemini."""
    print("ğŸ§  Generating analysis with Google Gemini...")
    
    genai.configure(api_key=os.environ["GEMINI_API_KEY"])
    model = genai.GenerativeModel('gemma-3-12b-it') # Usando modelo confirmado disponÃ­vel

    # Monta o prompt
    articles_text = ""
    for i, article in enumerate(articles):
        articles_text += f"\n\n--- Article {i+1} ({article['url']}) ---\n{article['content']}"

    prompt = f"""
    Atue como um analista de Venture Capital especializado no mercado Brasileiro (LatAm). 
    Analise os artigos abaixo e identifique **novas rodadas de investimento (Seed/Pre-Seed)** e **novas startups** promissoras.

    **Filtros de Qualidade:**
    - Priorize empresas brasileiras ou com operaÃ§Ã£o no Brasil.
    - Busque detalhes especÃ­ficos: Founders, Quem investiu (VCs), Valuation.
    - Ignore notÃ­cias genÃ©ricas de mercado ou anÃºncios corporativos sem deal flow.

    **Formato de SaÃ­da (Markdown):**
    Para cada deal relevante encontrado, estuture assim:

    ### ğŸ‡§ğŸ‡· [Nome da Startup] - [Tipo da Rodada: Pre-Seed/Seed/Series A]
    - **O Deal:** Resumo de 1 linha sobre o aporte (Valor captado).
    - **Quem sÃ£o:** DescriÃ§Ã£o curta do que a empresa faz.
    - **Founders:** [Nomes dos fundadores]
    - **Investidores (VCs):** [Lista de fundos que entraram]
    - **Valuation:** [Valor se disponÃ­vel, ou "NÃ£o divulgado"]
    - **Tese:** Por que isso Ã© interessante? (1 linha)
    - [Fonte Original](URL)

    **Sinais Fracos (Early Stage):**
    - Liste brevemente startups que acabaram de nascer ou estÃ£o em stealth, se houver menÃ§Ã£o.

    Artigos para anÃ¡lise:
    {articles_text}
    """

    try:
        response = model.generate_content(prompt)
        if not response.text:
            raise ValueError("Gemini returned empty response")
        return response.text
    except Exception as e:
        print(f"âŒ Erro na geraÃ§Ã£o com Gemini: {e}")
        print("âš ï¸ Falling back to raw crawl data...")
        
        # Fallback: Monta um email com os dados brutos do Crawl4AI
        fallback_content = "# âš ï¸ Gemini Failed - Raw Crawl Data\n\n"
        fallback_content += "> O modelo de IA falhou ao gerar o resumo. Abaixo estÃ£o os dados extraÃ­dos automaticamente.\n\n"
        
        for article in articles:
            # Limita o tamanho de cada artigo no fallback para nÃ£o ficar gigante
            snippet = article['content'][:500].replace('\n', ' ') + "..."
            fallback_content += f"### [{article['url']}]({article['url']})\n"
            fallback_content += f"{snippet}\n\n"
            
        return fallback_content

async def run_pipeline(dry_run=False):
    print(f"ğŸš€ Starting VC Intelligence Pipeline (Gemini Powered) {'[DRY RUN MODE]' if dry_run else ''} ...")
    
    # 1. Search with Tavily
    if dry_run:
        print("ğŸ” [DRY RUN] Skipping Tavily Search. Using mock URLs.")
        urls = ["https://techcrunch.com/mock-article-1", "https://venturebeat.com/mock-article-2"]
    else:
        tavily = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])
        print(f"ğŸ” Searching for: {SEARCH_TOPIC}")
        print(f"ğŸ¯ Strict Mode: Searching only in {len(TRUSTED_SOURCES)} trusted domains (Last 24h).")
        
        search_response = tavily.search(
            query=SEARCH_TOPIC,
            topic="news", # ForÃ§a busca de notÃ­cias recentes
            include_domains=TRUSTED_SOURCES,
            days=1, # Apenas notÃ­cias de ontem para hoje
            max_results=5 # Reduzido para evitar Rate Limit
        )
        urls = [result['url'] for result in search_response['results']]
        
    print(f"ğŸ”— Found {len(urls)} relevant URLs.")

    # 2. Crawl Content
    if dry_run:
        print("ğŸ•·ï¸ [DRY RUN] Skipping Crawl. Using mock content.")
        crawled_data = [
            {"url": "https://techcrunch.com/mock-article-1", "content": "# Mock Article 1\nStartup raises $50M."},
            {"url": "https://venturebeat.com/mock-article-2", "content": "# Mock Article 2\nAI Company acquired."}
        ]
    else:
        crawled_data = await crawl_urls(urls)
    
    if not crawled_data:
        print("âŒ No content crawled. Aborting.")
        return

     # 3. Summarize
    if dry_run:
         print("ğŸ§  [DRY RUN] Skipping Gemini Generation. Using mock summary.")
         import textwrap
         newsletter_md = textwrap.dedent("""
          ### [MOCK] Startup Mock Captou $50M
          - **O que aconteceu:** Rodada fictÃ­cia para teste.
          - **Por que importa:** ValidaÃ§Ã£o do modo dry-run.
          - [Ler Fonte](https://mock.com)
          """)
    else:
        newsletter_md = generate_newsletter(crawled_data)
    
    # 4. Send Email
    print("ğŸ“§ Sending email...")
    # No dry-run for email as requested? "funcionalidades prÃ©-envio". The user wants to test PRE-sending. 
    # But usually dry-run implies *not* sending or sending to safe target.
    # The user said: "gera um teste para as funcionalidades prÃ©-envio para nÃ£o consumir todas os crÃ©ditos de chamadas Ã s apis"
    # This implies they WANT to verify the flow, maybe even send the email, but avoid Tavily/Gemini usage.
    # So I will SEND the email even in dry-run, because sending is cheap/free (Resend) and verifies the final delivery.
    
    if send_daily_briefing(newsletter_md, EMAIL_TO):
        print("ğŸ‰ Pipeline completed successfully!")
    else:
        print("âš ï¸ Pipeline finished but email failed.")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="VC News Agent Pipeline")
    parser.add_argument("--dry-run", action="store_true", help="Run in test mode without using API credits (mocks Search and Summary)")
    args = parser.parse_args()

    asyncio.run(run_pipeline(dry_run=args.dry_run))
